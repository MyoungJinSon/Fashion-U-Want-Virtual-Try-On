{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1Q5rAG7Mb7MwnP2cDIIcb-O5iFyLyYa-2","authorship_tag":"ABX9TyP9JGyugIVWyrIodC26mbv5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"G4nLwPbNJznz"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# 3. DensePose"],"metadata":{"id":"BJ9mYR9eUirR"}},{"cell_type":"markdown","source":["(1) get repo of detectron2"],"metadata":{"id":"Y_jZLSfb8XAC"}},{"cell_type":"markdown","source":["- 수정된 apply_net.py 사용할 때는 구글드라이브에 저장한 이미 수정된 detectron2 불러와서 사용"],"metadata":{"id":"Ln6TsWa0CdLS"}},{"cell_type":"code","source":["#수정된 detectron2 불러오기\n","#!cp -r /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/detectron2 /content/detectron2\n"],"metadata":{"id":"xXXtDAg59en_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/facebookresearch/detectron2"],"metadata":{"id":"zSYI-r5ji5lI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732027752727,"user_tz":-540,"elapsed":2760,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"507f1a6b-a7fc-424e-ea35-0e2b0ccd0c78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'detectron2'...\n","remote: Enumerating objects: 15806, done.\u001b[K\n","remote: Counting objects: 100% (63/63), done.\u001b[K\n","remote: Compressing objects: 100% (54/54), done.\u001b[K\n","remote: Total 15806 (delta 22), reused 38 (delta 9), pack-reused 15743 (from 1)\u001b[K\n","Receiving objects: 100% (15806/15806), 6.38 MiB | 13.52 MiB/s, done.\n","Resolving deltas: 100% (11516/11516), done.\n"]}]},{"cell_type":"markdown","source":["(2) install dependencies"],"metadata":{"id":"xB_Ensgp8YBG"}},{"cell_type":"code","source":["!python -m pip install -e detectron2"],"metadata":{"id":"13PbX0YAi5io","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1732028068081,"user_tz":-540,"elapsed":312361,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"87a48c7c-ca4a-4934-d8ce-591c1410acba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Obtaining file:///content/detectron2\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (11.0.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.8.0)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.5.0)\n","Collecting yacs>=0.1.8 (from detectron2==0.6)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.1.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.6)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.17.1)\n","Collecting fvcore<0.1.6,>=0.1.5 (from detectron2==0.6)\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iopath<0.1.10,>=0.1.7 (from detectron2==0.6)\n","  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n","Collecting omegaconf<2.4,>=2.1 (from detectron2==0.6)\n","  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n","Collecting hydra-core>=1.1 (from detectron2==0.6)\n","  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n","Collecting black (from detectron2==0.6)\n","  Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n","Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.1->detectron2==0.6)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting portalocker (from iopath<0.1.10,>=0.1.7->detectron2==0.6)\n","  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.2.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n","Collecting mypy-extensions>=0.4.3 (from black->detectron2==0.6)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting pathspec>=0.9.0 (from black->detectron2==0.6)\n","  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.6)\n","Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.1.0)\n","Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.67.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (4.25.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (75.1.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (3.0.2)\n","Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading black-24.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n","Building wheels for collected packages: fvcore, antlr4-python3-runtime\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61396 sha256=abab623e683b2e1c045d4ca37d8de0de8ed44001fa8500028eb15791cbe8be7b\n","  Stored in directory: /root/.cache/pip/wheels/01/c0/af/77c1cf53a1be9e42a52b48e5af2169d40ec2e89f7362489dd0\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144555 sha256=520369e2d68da793a8e67c257173e2e5f11660abeef4533b90f05d4773c4ea1b\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","Successfully built fvcore antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, yacs, portalocker, pathspec, omegaconf, mypy-extensions, iopath, hydra-core, black, fvcore, detectron2\n","  Running setup.py develop for detectron2\n","Successfully installed antlr4-python3-runtime-4.9.3 black-24.10.0 detectron2-0.6 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.0.0 omegaconf-2.3.0 pathspec-0.12.1 portalocker-3.0.0 yacs-0.1.8\n"]}]},{"cell_type":"markdown","source":["(3) install packages for DensePose"],"metadata":{"id":"zGHk01ep8YaJ"}},{"cell_type":"code","source":["%cd detectron2/projects/DensePose\n","!pip install av>=8.0.3 opencv-python-headless>=4.5.3.56 scipy>=1.5.4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXnQXeAe8LiZ","executionInfo":{"status":"ok","timestamp":1732028879922,"user_tz":-540,"elapsed":4834,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"bb8e1999-d7c9-4d50-a8f8-124345e11d9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/detectron2/projects/DensePose\n"]}]},{"cell_type":"markdown","source":["(4) Prepare your images\n","\n"],"metadata":{"id":"WgDAbaIK8dtg"}},{"cell_type":"code","source":["root_dir = '/content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test'\n","#image_path라는 이름의 폴더 만들어주고 이미지 넣어줌 => detectron2 실행 시 image_path라는 이름으로 넘겨주게 됨.\n","!mkdir ./image_path\n","!cp {root_dir}/pre-processing/image/*.jpg ./image_path/"],"metadata":{"id":"JDN7PT1ATSKR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["(5) Run"],"metadata":{"id":"P7oocO4l_oP8"}},{"cell_type":"markdown","source":["- ./densepose/vis/densepose_results.py 수정 line 322\n","  - alpha=0.7 to 1\n","  - inplace=True to False\n","\n","- ./densepose/vis/base.py 수정 line 40\n","  - image_target_bgr = image_bgr * 0\n","    \n","    **to**\n","      \n","      image_target_bgr = image_bgr\n","\n","      image_target_bgr *= 0\n","- apply_net.py 수정 line 286-287\n","\n","  - root_dir = '/content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test'\n","  \n","  - out_fname = f'{root_dir}/pre-processing/image-densepose/' + image_fpath.split('/')[-1]\n","        \n","  - out_dir = f'{root_dir}/pre-processing/image-densepose/'"],"metadata":{"id":"0iRbVpKsicoW"}},{"cell_type":"code","source":["!python apply_net.py show configs/densepose_rcnn_R_50_FPN_s1x.yaml \\\n","https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl \\\n","image_path dp_segm -v"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wwEfJWup8Ldt","executionInfo":{"status":"ok","timestamp":1732029949983,"user_tz":-540,"elapsed":10347,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"19cbc6f3-1435-47af-b7bb-280278dd1b77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[32m[11/19 15:25:42 apply_net]: \u001b[0mLoading config from configs/densepose_rcnn_R_50_FPN_s1x.yaml\n","\u001b[32m[11/19 15:25:42 apply_net]: \u001b[0mLoading model from https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl\n","\u001b[32m[11/19 15:25:44 apply_net]: \u001b[0mLoading data from image_path\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[32m[11/19 15:25:47 apply_net]: \u001b[0mProcessing image_path/00000_03.jpg\n","\u001b[32m[11/19 15:25:47 apply_net]: \u001b[0mOutput saved to /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test/pre-processing/image-densepose/00000_03.jpg\n","\u001b[32m[11/19 15:25:47 apply_net]: \u001b[0mProcessing image_path/00000_05.jpg\n","\u001b[32m[11/19 15:25:47 apply_net]: \u001b[0mOutput saved to /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test/pre-processing/image-densepose/00000_05.jpg\n","\u001b[32m[11/19 15:25:47 apply_net]: \u001b[0mProcessing image_path/00000_10.jpg\n","\u001b[32m[11/19 15:25:47 apply_net]: \u001b[0mOutput saved to /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test/pre-processing/image-densepose/00000_10.jpg\n","\u001b[32m[11/19 15:25:47 apply_net]: \u001b[0mProcessing image_path/00000_02.jpg\n","\u001b[32m[11/19 15:25:47 apply_net]: \u001b[0mOutput saved to /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test/pre-processing/image-densepose/00000_02.jpg\n","\u001b[32m[11/19 15:25:48 apply_net]: \u001b[0mProcessing image_path/00000_04.jpg\n","\u001b[32m[11/19 15:25:48 apply_net]: \u001b[0mOutput saved to /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test/pre-processing/image-densepose/00000_04.jpg\n","\u001b[32m[11/19 15:25:48 apply_net]: \u001b[0mProcessing image_path/00000_01.jpg\n","\u001b[32m[11/19 15:25:48 apply_net]: \u001b[0mOutput saved to /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test/pre-processing/image-densepose/00000_01.jpg\n","\u001b[32m[11/19 15:25:48 apply_net]: \u001b[0mProcessing image_path/00000_00.jpg\n","\u001b[32m[11/19 15:25:48 apply_net]: \u001b[0mOutput saved to /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test/pre-processing/image-densepose/00000_00.jpg\n"]}]},{"cell_type":"code","source":["#수정한 detectron2 따로 저장\n","#!cp -r /content/detectron2 /content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation\n"],"metadata":{"id":"hPD7bs568Wio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rREOGzAlDHxP","executionInfo":{"status":"ok","timestamp":1732030605973,"user_tz":-540,"elapsed":469,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"fb5cc1c7-e6c6-4b95-ca08-815d920c651d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"markdown","source":["# 4. Cloth Mask"],"metadata":{"id":"udw6nluoRmLV"}},{"cell_type":"markdown","source":["(1) install"],"metadata":{"id":"IF9eB5w4Rv_0"}},{"cell_type":"code","source":["!pip install carvekit_colab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"aoRlIXPp8LYB","executionInfo":{"status":"ok","timestamp":1732030208324,"user_tz":-540,"elapsed":5183,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"25706d0c-86ba-4252-f558-147fcac8f09d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting carvekit_colab\n","  Downloading carvekit_colab-4.1.2-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (2.32.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (2.5.1+cu121)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (11.0.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (0.20.1+cu121)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (4.10.0.84)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (1.26.4)\n","Collecting loguru (from carvekit_colab)\n","  Downloading loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n","Collecting uvicorn (from carvekit_colab)\n","  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n","Collecting fastapi (from carvekit_colab)\n","  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (2.9.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (8.1.7)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (4.66.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from carvekit_colab) (75.1.0)\n","Collecting aiofiles (from carvekit_colab)\n","  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n","Collecting python-multipart (from carvekit_colab)\n","  Downloading python_multipart-0.0.17-py3-none-any.whl.metadata (1.8 kB)\n","Collecting starlette<0.42.0,>=0.40.0 (from fastapi->carvekit_colab)\n","  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->carvekit_colab) (4.12.2)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->carvekit_colab) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->carvekit_colab) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->carvekit_colab) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->carvekit_colab) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->carvekit_colab) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->carvekit_colab) (2024.8.30)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->carvekit_colab) (3.16.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->carvekit_colab) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->carvekit_colab) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->carvekit_colab) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->carvekit_colab) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->carvekit_colab) (1.3.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->carvekit_colab) (0.14.0)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi->carvekit_colab) (3.7.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->carvekit_colab) (3.0.2)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi->carvekit_colab) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi->carvekit_colab) (1.2.2)\n","Downloading carvekit_colab-4.1.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n","Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading loguru-0.7.2-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.17-py3-none-any.whl (24 kB)\n","Downloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: uvicorn, python-multipart, loguru, aiofiles, starlette, fastapi, carvekit_colab\n","Successfully installed aiofiles-24.1.0 carvekit_colab-4.1.2 fastapi-0.115.5 loguru-0.7.2 python-multipart-0.0.17 starlette-0.41.3 uvicorn-0.32.0\n"]}]},{"cell_type":"markdown","source":["(2) Download models"],"metadata":{"id":"6XBGs_b4RzAR"}},{"cell_type":"code","source":["from carvekit.ml.files.models_loc import download_all\n","download_all();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"so7acJ-sRsfD","executionInfo":{"status":"ok","timestamp":1732030357211,"user_tz":-540,"elapsed":125388,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"a8207a9f-54e8-4d61-eff0-b2a9949cc4fe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading u2net.pth model: 1377273it [00:21, 62794.00it/s]\n","Downloading fba_matting.pth model: 1084688it [00:16, 67703.27it/s]\n","Downloading deeplab.pth model: 1910513it [00:27, 69508.13it/s]\n","Downloading basnet.pth model: 2722581it [00:35, 76416.54it/s]\n","Downloading tracer_b7.pth model: 2084885it [00:19, 109080.95it/s]\n"]}]},{"cell_type":"markdown","source":["(3) Prepare cloth images\n","- 경로만 수정"],"metadata":{"id":"CrPTAEklR515"}},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"9T94FzPfuYwo","executionInfo":{"status":"ok","timestamp":1732030610516,"user_tz":-540,"elapsed":469,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"aa4b4b94-7cc2-495d-8984-ccb0211ba1df"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["root_dir = '/content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation/test'"],"metadata":{"id":"12sAwSVD6SJK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["(4) Run"],"metadata":{"id":"GoIorx7ESCMU"}},{"cell_type":"code","source":["!cp /content/cloth/0000*.jpg /content/cloth_1/"],"metadata":{"id":"CqYnQJFN_CTS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#title Upload images from your computer\n","#markdown Description of parameters\n","#markdown - `SHOW_FULLSIZE`  - Shows image in full size (may take a long time to load)\n","#markdown - `PREPROCESSING_METHOD`  - Preprocessing method\n","#markdown - `SEGMENTATION_NETWORK`  - Segmentation network. Use `u2net` for hairs-like objects and `tracer_b7` for objects\n","#markdown - `POSTPROCESSING_METHOD`  - Postprocessing method\n","#markdown - `SEGMENTATION_MASK_SIZE` - Segmentation mask size. Use 640 for Tracer B7 and 320 for U2Net\n","#markdown - `TRIMAP_DILATION`  - The size of the offset radius from the object mask in pixels when forming an unknown area\n","#markdown - `TRIMAP_EROSION`  - The number of iterations of erosion that the object's mask will be subjected to before forming an unknown area\n","\n","import os\n","import numpy as np\n","from PIL import Image, ImageOps\n","from carvekit.web.schemas.config import MLConfig\n","from carvekit.web.utils.init_utils import init_interface\n","\n","SHOW_FULLSIZE = False #param {type:\"boolean\"}\n","PREPROCESSING_METHOD = \"none\" #param [\"stub\", \"none\"]\n","SEGMENTATION_NETWORK = \"u2net\" #param [\"u2net\", \"deeplabv3\", \"basnet\", \"tracer_b7\"]\n","POSTPROCESSING_METHOD = \"none\" #param [\"fba\", \"none\"]\n","SEGMENTATION_MASK_SIZE = 320 #param [\"640\", \"320\"] {type:\"raw\", allow-input: true}\n","TRIMAP_DILATION = 15 #param {type:\"integer\"} #30\n","TRIMAP_EROSION = 3 #param {type:\"integer\"} #5\n","DEVICE = 'cuda' # 'cpu','cuda'\n","\n","config = MLConfig(segmentation_network=SEGMENTATION_NETWORK,\n","                  preprocessing_method=PREPROCESSING_METHOD,\n","                  postprocessing_method=POSTPROCESSING_METHOD,\n","                  seg_mask_size=SEGMENTATION_MASK_SIZE,\n","                  trimap_dilation=TRIMAP_DILATION,\n","                  trimap_erosion=TRIMAP_EROSION,\n","                  device=DEVICE)\n","\n","interface = init_interface(config)\n","\n","imgs = []\n","root = f'{root_dir}/pre-processing/cloth/'\n","for name in os.listdir(root):\n","    imgs.append(root + '/' + name)\n","\n","images = interface(imgs)\n","for i, im in enumerate(images):\n","    img = np.array(im)\n","    img = img[...,:3] # no transparency\n","    idx = (img[...,0]==0)&(img[...,1]==0)&(img[...,2]==0) # background 0 or 130, just try it\n","    img = np.ones(idx.shape)*255\n","    img[idx] = 0\n","    im = Image.fromarray(np.uint8(img), 'L')\n","    im.save(f'{root_dir}/pre-processing/cloth-mask/{imgs[i].split(\"/\")[-1].split(\".\")[0]}.jpg')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqsgdAXpRsXj","executionInfo":{"status":"ok","timestamp":1732030521461,"user_tz":-540,"elapsed":5830,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"18f815f6-4196-4b3e-c012-8c846e22d70a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/carvekit/ml/wrap/u2net.py:55: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  torch.load(u2net_full_pretrained(), map_location=self.device)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NCEssTXZRsRZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. Human Agnostic"],"metadata":{"id":"vcREroRdSSHJ"}},{"cell_type":"markdown","source":["(1) install"],"metadata":{"id":"IqHkOCBWSXM1"}},{"cell_type":"code","source":["!pip install Pillow tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1UBRRGTURsO5","executionInfo":{"status":"ok","timestamp":1732035475780,"user_tz":-540,"elapsed":3853,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"01c2b98f-36a7-4b93-fdd8-ba46be51c24e"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n"]}]},{"cell_type":"markdown","source":["(2) Prepare data\n","\n","(3) Run"],"metadata":{"id":"Bs69WZ6_SZN7"}},{"cell_type":"code","source":["import json\n","from os import path as osp\n","import os\n","import numpy as np\n","from PIL import Image, ImageDraw\n","from tqdm import tqdm\n","\n","def get_img_agnostic(img, parse, pose_data):\n","    parse_array = np.array(parse)\n","    parse_head = ((parse_array == 4).astype(np.float32) +\n","                    (parse_array == 13).astype(np.float32))\n","    parse_lower = ((parse_array == 9).astype(np.float32) +\n","                    (parse_array == 12).astype(np.float32) +\n","                    (parse_array == 16).astype(np.float32) +\n","                    (parse_array == 17).astype(np.float32) +\n","                    (parse_array == 18).astype(np.float32) +\n","                    (parse_array == 19).astype(np.float32))\n","\n","\n","    agnostic = img.copy()\n","    agnostic_draw = ImageDraw.Draw(agnostic)\n","\n","    length_a = np.linalg.norm(pose_data[5] - pose_data[2])\n","    length_b = np.linalg.norm(pose_data[12] - pose_data[9])\n","    point = (pose_data[9] + pose_data[12]) / 2\n","    pose_data[9] = point + (pose_data[9] - point) / length_b * length_a\n","    pose_data[12] = point + (pose_data[12] - point) / length_b * length_a\n","    r = int(length_a / 16) + 1\n","\n","    # mask arms\n","    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 5]], 'gray', width=r*10)\n","    for i in [2, 5]:\n","        pointx, pointy = pose_data[i]\n","        agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n","    for i in [3, 4, 6, 7]:\n","        if (pose_data[i - 1, 0] == 0.0 and pose_data[i - 1, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n","            continue\n","        agnostic_draw.line([tuple(pose_data[j]) for j in [i - 1, i]], 'gray', width=r*10)\n","        pointx, pointy = pose_data[i]\n","        agnostic_draw.ellipse((pointx-r*5, pointy-r*5, pointx+r*5, pointy+r*5), 'gray', 'gray')\n","\n","    # mask torso\n","    for i in [9, 12]:\n","        pointx, pointy = pose_data[i]\n","        agnostic_draw.ellipse((pointx-r*3, pointy-r*6, pointx+r*3, pointy+r*6), 'gray', 'gray')\n","    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 9]], 'gray', width=r*6)\n","    agnostic_draw.line([tuple(pose_data[i]) for i in [5, 12]], 'gray', width=r*6)\n","    agnostic_draw.line([tuple(pose_data[i]) for i in [9, 12]], 'gray', width=r*12)\n","    agnostic_draw.polygon([tuple(pose_data[i]) for i in [2, 5, 12, 9]], 'gray', 'gray')\n","\n","    # mask neck\n","    pointx, pointy = pose_data[1]\n","    agnostic_draw.rectangle((pointx-r*7, pointy-r*7, pointx+r*7, pointy+r*7), 'gray', 'gray')\n","    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_head * 255), 'L'))\n","    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_lower * 255), 'L'))\n","\n","    return agnostic\n","\n","if __name__ ==\"__main__\":\n","    data_root_path = '/content/drive/MyDrive/Colab_Notebooks/likelion_AIEngineer/Clothing_Segmentation'\n","    data_path = f'{data_root_path}/test_pre-processing/test'\n","    output_path = f'{data_root_path}/test_pre-processing/test/image-parse-agnostic-v3.2'\n","\n","    os.makedirs(output_path, exist_ok=True)\n","\n","    for im_name in tqdm(os.listdir(osp.join(data_path, 'image'))):\n","        # .ipynb_checkpoints 폴더를 건너뜁니다.\n","        if im_name == '.ipynb_checkpoints':\n","            continue\n","        # load pose image\n","        pose_name = im_name.replace('.jpg', '_keypoints.json')\n","\n","        try:\n","            with open(osp.join(data_path, 'openpose_json', pose_name), 'r') as f:\n","                pose_label = json.load(f)\n","                pose_data = pose_label['people'][0]['pose_keypoints_2d']\n","                pose_data = np.array(pose_data)\n","                pose_data = pose_data.reshape((-1, 3))[:, :2]\n","        except IndexError:\n","            print(pose_name)\n","            continue\n","\n","        # load parsing image\n","        im = Image.open(osp.join(data_path, 'image', im_name))\n","        label_name = im_name.replace('.jpg', '.png')\n","        #label_name = im_name.replace('.png', '.jpg')\n","        im_label = Image.open(osp.join(data_path, 'image-parse-v3', label_name))\n","\n","        agnostic = get_img_agnostic(im, im_label, pose_data)\n","        filename, ext = os.path.splitext(im_name)  # 파일 이름과 확장자 분리\n","        agnostic.save(osp.join(output_path, filename + '.png'))  # PNG로 저장\n","        #agnostic.save(osp.join(output_path, im_name))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPjK4xli8LOK","executionInfo":{"status":"ok","timestamp":1732036207641,"user_tz":-540,"elapsed":972,"user":{"displayName":"손명진","userId":"04297256498263228154"}},"outputId":"8b244c34-32a7-4faa-a3cc-d38a5a41add1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 8/8 [00:00<00:00, 10.16it/s]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"uHDYXxnzSb3r"},"execution_count":null,"outputs":[]}]}