{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: /Users/parkyunsu/Downloads/00022_00.jpg\n",
      "Saved result to: pre-processing/openpose_img/00022_00_rendered.png\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from src import model\n",
    "from src import util\n",
    "from src.body import Body\n",
    "from src.hand import Hand\n",
    "\n",
    "\n",
    "def load_model(use_hand=False):\n",
    "    model_path = 'model/pose_iter_584000.caffemodel.pt'\n",
    "    body_estimation = Body(model_path, 'body25')\n",
    "    if use_hand:\n",
    "        hand_estimation = Hand('model/hand_pose_model.pth')\n",
    "    else:\n",
    "        hand_estimation = None\n",
    "    return body_estimation, hand_estimation\n",
    "\n",
    "\n",
    "def inference(oriImg, test_image_path, body_estimation, hand_estimation, output_path='.'):\n",
    "    candidate, subset = body_estimation(oriImg)\n",
    "    \n",
    "    # 검정 배경 생성 (원본 이미지 크기와 동일)\n",
    "    canvas = np.zeros_like(oriImg)\n",
    "\n",
    "    # Body pose 그리기\n",
    "    canvas = util.draw_bodypose(canvas, candidate, subset, 'body25')\n",
    "\n",
    "    if hand_estimation is not None:\n",
    "        # Detect hand\n",
    "        hands_list = util.handDetect(candidate, subset, oriImg)\n",
    "        all_hand_peaks = []\n",
    "        for x, y, w, is_left in hands_list:\n",
    "            peaks = hand_estimation(oriImg[y:y+w, x:x+w, :])\n",
    "            peaks[:, 0] = np.where(\n",
    "                peaks[:, 0] == 0, peaks[:, 0], peaks[:, 0]+x)\n",
    "            peaks[:, 1] = np.where(\n",
    "                peaks[:, 1] == 0, peaks[:, 1], peaks[:, 1]+y)\n",
    "            all_hand_peaks.append(peaks)\n",
    "        canvas = util.draw_handpose(canvas, all_hand_peaks)\n",
    "\n",
    "    # 결과 저장: 저장 이름을 요청한 형식으로 변경\n",
    "    img_basename = os.path.basename(test_image_path).split('.')[0]  # 파일 이름에서 확장자 제거\n",
    "    result_path = os.path.join(output_path, f'{img_basename}_rendered.png')\n",
    "    cv2.imwrite(result_path, canvas)\n",
    "    print(f\"Saved result to: {result_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    body_estimation, hand_estimation = load_model(use_hand=True)\n",
    "    \n",
    "    # 입력 및 출력 경로 설정\n",
    "    input_path = 'input/image'\n",
    "    output_path = 'pre-processing/openpose_img'\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # 입력 디렉토리 내 모든 이미지 처리\n",
    "    for test_image_name in os.listdir(input_path):\n",
    "        if not test_image_name.endswith(('.jpg', '.png')):  # 이미지 파일만 처리\n",
    "            continue\n",
    "        \n",
    "        test_image_path = os.path.join(input_path, test_image_name)\n",
    "        oriImg = cv2.imread(test_image_path)  # B,G,R order\n",
    "        \n",
    "        print(f'Processing: {test_image_path}')\n",
    "        inference(oriImg, test_image_path, body_estimation, hand_estimation, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON saved at pre-processing/openpose_json/00022_00_keypoints.json\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from src import util\n",
    "from src.body import Body\n",
    "from src.hand import Hand\n",
    "\n",
    "\n",
    "def load_model(use_hand=False):\n",
    "    model_path = 'model/pose_iter_584000.caffemodel.pt'\n",
    "    body_estimation = Body(model_path, 'body25')\n",
    "    hand_estimation = Hand('model/hand_pose_model.pth') if use_hand else None\n",
    "    return body_estimation, hand_estimation\n",
    "\n",
    "\n",
    "def inference_and_save_json(image_path, body_estimation, hand_estimation, output_path):\n",
    "    oriImg = cv2.imread(image_path)  # B,G,R order\n",
    "    if oriImg is None:\n",
    "        print(f\"Error: Could not read image from path {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Body estimation\n",
    "    candidate, subset = body_estimation(oriImg)\n",
    "\n",
    "    # Hand estimation\n",
    "    all_hand_peaks = []\n",
    "    if hand_estimation is not None:\n",
    "        hands_list = util.handDetect(candidate, subset, oriImg)\n",
    "        for x, y, w, is_left in hands_list:\n",
    "            peaks = hand_estimation(oriImg[y:y+w, x:x+w, :])\n",
    "            peaks[:, 0] = np.where(peaks[:, 0] == 0, peaks[:, 0], peaks[:, 0]+x)\n",
    "            peaks[:, 1] = np.where(peaks[:, 1] == 0, peaks[:, 1], peaks[:, 1]+y)\n",
    "            all_hand_peaks.append(peaks)\n",
    "\n",
    "    # Output file paths\n",
    "    img_basename = os.path.basename(image_path).split('.')[0]  # ex: 00022_00\n",
    "    json_filename = f\"{img_basename}_keypoints.json\"\n",
    "    json_path = os.path.join(output_path, json_filename)\n",
    "\n",
    "    # Prepare JSON output\n",
    "    json_data = {\"version\": 1.3, \"people\": []}\n",
    "    for person in subset:\n",
    "        person_data = {\n",
    "            \"person_id\": [-1],\n",
    "            \"pose_keypoints_2d\": [],\n",
    "            \"face_keypoints_2d\": [],\n",
    "            \"hand_left_keypoints_2d\": [],\n",
    "            \"hand_right_keypoints_2d\": [],\n",
    "            \"pose_keypoints_3d\": [],\n",
    "            \"face_keypoints_3d\": [],\n",
    "            \"hand_left_keypoints_3d\": [],\n",
    "            \"hand_right_keypoints_3d\": []\n",
    "        }\n",
    "\n",
    "        # Add body keypoints\n",
    "        for idx in range(len(candidate)):\n",
    "            if idx in person[:len(candidate)]:\n",
    "                keypoint = candidate[int(idx)]\n",
    "                person_data[\"pose_keypoints_2d\"].extend([float(keypoint[0]), float(keypoint[1]), float(keypoint[2])])\n",
    "            else:\n",
    "                person_data[\"pose_keypoints_2d\"].extend([0.0, 0.0, 0.0])  # Default for missing points\n",
    "\n",
    "        # Add hand keypoints\n",
    "        if len(all_hand_peaks) > 0:\n",
    "            if len(all_hand_peaks) > 0:  # Left hand\n",
    "                for peak in all_hand_peaks[0]:\n",
    "                    person_data[\"hand_left_keypoints_2d\"].extend(\n",
    "                        [float(peak[0]), float(peak[1]), 1.0 if peak[0] > 0 else 0.0]\n",
    "                    )\n",
    "            else:\n",
    "                person_data[\"hand_left_keypoints_2d\"].extend([0.0] * 63)\n",
    "            if len(all_hand_peaks) > 1:  # Right hand\n",
    "                for peak in all_hand_peaks[1]:\n",
    "                    person_data[\"hand_right_keypoints_2d\"].extend(\n",
    "                        [float(peak[0]), float(peak[1]), 1.0 if peak[0] > 0 else 0.0]\n",
    "                    )\n",
    "            else:\n",
    "                person_data[\"hand_right_keypoints_2d\"].extend([0.0] * 63)\n",
    "\n",
    "        json_data[\"people\"].append(person_data)\n",
    "\n",
    "    # Save JSON\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    with open(json_path, \"w\") as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "    print(f\"JSON saved at {json_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load models\n",
    "    body_estimation, hand_estimation = load_model(use_hand=True)\n",
    "\n",
    "    # 입력 및 출력 경로 설정\n",
    "    input_path = 'input/image'\n",
    "    output_path = 'pre-processing/openpose_json'\n",
    "\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # 입력 디렉토리 내 모든 이미지 처리\n",
    "    for image_name in os.listdir(input_path):\n",
    "        if not image_name.endswith(('.jpg', '.png')):  # 이미지 파일만 처리\n",
    "            continue\n",
    "        \n",
    "        image_path = os.path.join(input_path, image_name)\n",
    "        print(f'Processing: {image_path}')\n",
    "        inference_and_save_json(image_path, body_estimation, hand_estimation, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Self-Correction-Human-Parsing'...\n",
      "remote: Enumerating objects: 722, done.\u001b[K\n",
      "remote: Counting objects: 100% (175/175), done.\u001b[K\n",
      "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
      "remote: Total 722 (delta 74), reused 64 (delta 64), pack-reused 547 (from 1)\u001b[K\n",
      "Receiving objects: 100% (722/722), 3.88 MiB | 21.14 MiB/s, done.\n",
      "Resolving deltas: 100% (150/150), done.\n",
      "/Users/parkyunsu/.Trash/Self-Correction-Human-Parsing/Self-Correction-Human-Parsing\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PeikeLi/Self-Correction-Human-Parsing\n",
    "%cd Self-Correction-Human-Parsing\n",
    "!mkdir checkpoints\n",
    "!mkdir inputs\n",
    "!mkdir outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from gdown) (4.67.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from requests[socks]->gdown) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from requests[socks]->gdown) (2024.8.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: ninja in /Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages (1.11.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!pip install ninja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "dataset = 'lip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH\n",
      "From (redirected): https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH&confirm=t&uuid=1de7ddae-287f-4df1-8ce8-ff59d0c4cf29\n",
      "To: /Users/parkyunsu/.Trash/Self-Correction-Human-Parsing/Self-Correction-Human-Parsing/checkpoints/final.pth\n",
      "100%|██████████| 267M/267M [00:08<00:00, 30.8MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'checkpoints/final.pth'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if dataset == 'lip':\n",
    "    url = 'https://drive.google.com/uc?id=1k4dllHpu0bdx38J7H28rVVLpU-kOHmnH'\n",
    "elif dataset == 'atr':\n",
    "    url = 'https://drive.google.com/uc?id=1ruJg4lqR_jgQPj-9K0PP-L2vJERYOxLP'\n",
    "elif dataset == 'pascal':\n",
    "    url = 'https://drive.google.com/uc?id=1E5YwNKW2VOEayK9mWCS3Kpsxf-3z04ZE'\n",
    "\n",
    "output = 'checkpoints/final.pth'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: python3 simple_extractor.py --dataset 'lip' --model-restore 'checkpoints/final.pth' --input-dir '/Users/parkyunsu/Downloads/00022_00.jpg' --output-dir 'pre-processing/image-parse'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"simple_extractor.py\", line 24, in <module>\n",
      "    import networks\n",
      "  File \"/Users/parkyunsu/.Trash/Self-Correction-Human-Parsing/Self-Correction-Human-Parsing/networks/__init__.py\", line 3, in <module>\n",
      "    from networks.AugmentCE2P import resnet101\n",
      "  File \"/Users/parkyunsu/.Trash/Self-Correction-Human-Parsing/Self-Correction-Human-Parsing/networks/AugmentCE2P.py\", line 21, in <module>\n",
      "    from modules import InPlaceABNSync\n",
      "  File \"/Users/parkyunsu/.Trash/Self-Correction-Human-Parsing/Self-Correction-Human-Parsing/modules/__init__.py\", line 1, in <module>\n",
      "    from .bn import ABN, InPlaceABN, InPlaceABNSync\n",
      "  File \"/Users/parkyunsu/.Trash/Self-Correction-Human-Parsing/Self-Correction-Human-Parsing/modules/bn.py\", line 10, in <module>\n",
      "    from .functions import *\n",
      "  File \"/Users/parkyunsu/.Trash/Self-Correction-Human-Parsing/Self-Correction-Human-Parsing/modules/functions.py\", line 10, in <module>\n",
      "    _backend = load(name=\"inplace_abn\",\n",
      "  File \"/Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages/torch/utils/cpp_extension.py\", line 1312, in load\n",
      "    return _jit_compile(\n",
      "  File \"/Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages/torch/utils/cpp_extension.py\", line 1722, in _jit_compile\n",
      "    _write_ninja_file_and_build_library(\n",
      "  File \"/Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages/torch/utils/cpp_extension.py\", line 1811, in _write_ninja_file_and_build_library\n",
      "    extra_ldflags = _prepare_ldflags(\n",
      "  File \"/Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages/torch/utils/cpp_extension.py\", line 1900, in _prepare_ldflags\n",
      "    if (not os.path.exists(_join_cuda_home(extra_lib_dir)) and\n",
      "  File \"/Users/parkyunsu/anaconda3/envs/fs/lib/python3.8/site-packages/torch/utils/cpp_extension.py\", line 2416, in _join_cuda_home\n",
      "    raise OSError('CUDA_HOME environment variable is not set. '\n",
      "OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Input and output paths\n",
    "input_dir = 'input/image'  # 디렉토리 내 모든 이미지 처리\n",
    "output_path = 'pre-processing/image-parse'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Process each image in the input directory\n",
    "for image_name in os.listdir(input_dir):\n",
    "    if not image_name.endswith(('.jpg', '.png')):  # 이미지 파일만 처리\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(input_dir, image_name)\n",
    "    command = f\"python3 simple_extractor.py --dataset 'lip' --model-restore 'checkpoints/final.pth' --input-dir '{input_path}' --output-dir '{output_path}'\"\n",
    "\n",
    "    # Execute the command\n",
    "    print(f\"Running command: {command}\")\n",
    "    os.system(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'detectron2'...\n",
      "remote: Enumerating objects: 15806, done.\u001b[K\n",
      "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
      "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
      "remote: Total 15806 (delta 22), reused 38 (delta 9), pack-reused 15743 (from 1)\u001b[K\n",
      "Receiving objects: 100% (15806/15806), 6.38 MiB | 22.44 MiB/s, done.\n",
      "Resolving deltas: 100% (11518/11518), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: detectron2 is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install -e detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'detectron2/projects/DensePose'\n",
      "/Users/parkyunsu/.Trash/Self-Correction-Human-Parsing/Self-Correction-Human-Parsing/detectron2/projects/DensePose\n",
      "zsh:1: 8.0.3 not found\n"
     ]
    }
   ],
   "source": [
    "%cd detectron2/projects/DensePose\n",
    "!pip install av>=8.0.3 opencv-python-headless>=4.5.3.56 scipy>=1.5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: \n",
      "python apply_net.py show configs/densepose_rcnn_R_50_FPN_s1x.yaml https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl ./image_path dp_segm -v --output-dir pre-processing/image-densepose\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"apply_net.py\", line 12, in <module>\n",
      "    from detectron2.config import CfgNode, get_cfg\n",
      "ModuleNotFoundError: No module named 'detectron2'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Input and output paths\n",
    "input_path = '/Users/parkyunsu/Downloads/00022_00.jpg'\n",
    "output_path = 'pre-processing/image-densepose'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Copy input image to a temporary directory for processing\n",
    "temp_image_dir = \"./image_path\"\n",
    "if os.path.exists(temp_image_dir):\n",
    "    os.system(f\"rm -rf {temp_image_dir}\")\n",
    "os.makedirs(temp_image_dir)\n",
    "\n",
    "# Copy the input image to the temporary directory\n",
    "os.system(f\"cp {input_path} {temp_image_dir}/\")\n",
    "\n",
    "# Run DensePose inference\n",
    "command = f\"\"\"\n",
    "python apply_net.py show configs/densepose_rcnn_R_50_FPN_s1x.yaml \\\n",
    "https://dl.fbaipublicfiles.com/densepose/densepose_rcnn_R_50_FPN_s1x/165712039/model_final_162be9.pkl \\\n",
    "{temp_image_dir} dp_segm -v --output-dir {output_path}\n",
    "\"\"\"\n",
    "\n",
    "# Execute the command\n",
    "print(f\"Running command: {command}\")\n",
    "os.system(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install carvekit_colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from carvekit.ml.files.models_loc import download_all\n",
    "download_all();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from carvekit.web.schemas.config import MLConfig\n",
    "from carvekit.web.utils.init_utils import init_interface\n",
    "\n",
    "# 설정\n",
    "SHOW_FULLSIZE = False\n",
    "PREPROCESSING_METHOD = \"none\"\n",
    "SEGMENTATION_NETWORK = \"u2net\"\n",
    "POSTPROCESSING_METHOD = \"fba\"\n",
    "SEGMENTATION_MASK_SIZE = 320\n",
    "TRIMAP_DILATION = 30\n",
    "TRIMAP_EROSION = 5\n",
    "DEVICE = 'cpu'\n",
    "\n",
    "# 경로 설정\n",
    "input_path = 'input/cloth'\n",
    "output_path = 'pre-processing/cloth-mask'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# CarveKit 설정\n",
    "config = MLConfig(segmentation_network=SEGMENTATION_NETWORK,\n",
    "                  preprocessing_method=PREPROCESSING_METHOD,\n",
    "                  postprocessing_method=POSTPROCESSING_METHOD,\n",
    "                  seg_mask_size=SEGMENTATION_MASK_SIZE,\n",
    "                  trimap_dilation=TRIMAP_DILATION,\n",
    "                  trimap_erosion=TRIMAP_EROSION,\n",
    "                  device=DEVICE)\n",
    "\n",
    "interface = init_interface(config)\n",
    "\n",
    "# 입력 이미지 처리\n",
    "imgs = [os.path.join(input_path, img) for img in os.listdir(input_path) if img.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# Segmentation 실행\n",
    "images = interface(imgs)\n",
    "\n",
    "# 결과 저장\n",
    "for img_path, im in zip(imgs, images):\n",
    "    img = np.array(im)\n",
    "    idx = ((img[..., 0] == 0) & (img[..., 1] == 0) & (img[..., 2] == 0)) | \\\n",
    "          ((img[..., 0] == 130) & (img[..., 1] == 130) & (img[..., 2] == 130))\n",
    "\n",
    "    img = np.ones(idx.shape) * 255\n",
    "    img[idx] = 0\n",
    "    im = Image.fromarray(np.uint8(img), 'L')\n",
    "    im.save(os.path.join(output_path, os.path.basename(img_path).split(\".\")[0] + '.jpg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os import path as osp\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 입력으로 분할된 이미지(im_parse)와 포즈 데이터(pose_data)를 받아, 지정된 부위를 마스킹한 결과를 반환\n",
    "def get_im_parse_agnostic(im_parse, pose_data, w=768, h=1024):\n",
    "    label_array = np.array(im_parse)\n",
    "    parse_upper = ((label_array == 5).astype(np.float32) +\n",
    "                   (label_array == 6).astype(np.float32) +\n",
    "                   (label_array == 7).astype(np.float32))  # 상체(5, 6, 7 레이블)와 목(10 레이블)을 마스킹할 영역으로 지정\n",
    "    parse_neck = (label_array == 10).astype(np.float32)\n",
    "\n",
    "    r = 10\n",
    "    agnostic = im_parse.copy()  # 마스킹된 이미지\n",
    "\n",
    "    # mask arms\n",
    "    for parse_id, pose_ids in [(14, [2, 5, 6, 7]), (15, [5, 2, 3, 4])]:\n",
    "        mask_arm = Image.new('L', (w, h), 'black')\n",
    "        mask_arm_draw = ImageDraw.Draw(mask_arm)\n",
    "        i_prev = pose_ids[0]\n",
    "        for i in pose_ids[1:]:\n",
    "            if (pose_data[i_prev, 0] == 0.0 and pose_data[i_prev, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n",
    "                continue\n",
    "            mask_arm_draw.line([tuple(pose_data[j]) for j in [i_prev, i]], 'white', width=r * 10)\n",
    "            pointx, pointy = pose_data[i]\n",
    "            radius = r * 4 if i == pose_ids[-1] else r * 15\n",
    "            mask_arm_draw.ellipse((pointx - radius, pointy - radius, pointx + radius, pointy + radius), 'white', 'white')\n",
    "            i_prev = i\n",
    "        parse_arm = (np.array(mask_arm) / 255) * (label_array == parse_id).astype(np.float32)\n",
    "        agnostic.paste(0, None, Image.fromarray(np.uint8(parse_arm * 255), 'L'))\n",
    "\n",
    "    # mask torso & neck\n",
    "    agnostic.paste(0, None, Image.fromarray(np.uint8(parse_upper * 255), 'L'))\n",
    "    agnostic.paste(0, None, Image.fromarray(np.uint8(parse_neck * 255), 'L'))\n",
    "\n",
    "    return agnostic\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 입력 및 출력 경로 설정\n",
    "    input_image_path = 'input/image'  # 변경된 경로\n",
    "    input_pose_path = 'pre-processing/openpose_json'\n",
    "    input_parse_path = 'pre-processing/image-parse'\n",
    "    output_path = 'pre-processing/image-parse-agnostic'\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for im_name in tqdm(os.listdir(input_image_path)):\n",
    "        if not im_name.endswith('.jpg'):\n",
    "            continue\n",
    "\n",
    "        # 포즈 데이터 로드\n",
    "        pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
    "        try:\n",
    "            with open(osp.join(input_pose_path, pose_name), 'r') as f:\n",
    "                pose_label = json.load(f)\n",
    "                pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
    "                pose_data = np.array(pose_data).reshape((-1, 3))[:, :2]\n",
    "        except (IndexError, KeyError, FileNotFoundError) as e:\n",
    "            print(f\"Error processing pose data for {pose_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 분할 이미지 로드\n",
    "        parse_name = im_name\n",
    "        try:\n",
    "            im_parse = Image.open(osp.join(input_parse_path, parse_name))\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error processing parse image for {parse_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 마스킹 처리\n",
    "        agnostic = get_im_parse_agnostic(im_parse, pose_data)\n",
    "\n",
    "        # 결과 저장\n",
    "        output_file_path = osp.join(output_path, parse_name)\n",
    "        agnostic.save(output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from os import path as osp\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_img_agnostic(img, parse, pose_data):\n",
    "    parse_array = np.array(parse)\n",
    "    parse_head = ((parse_array == 4).astype(np.float32) +\n",
    "                  (parse_array == 13).astype(np.float32))\n",
    "    parse_lower = ((parse_array == 9).astype(np.float32) +\n",
    "                   (parse_array == 12).astype(np.float32) +\n",
    "                   (parse_array == 16).astype(np.float32) +\n",
    "                   (parse_array == 17).astype(np.float32) +\n",
    "                   (parse_array == 18).astype(np.float32) +\n",
    "                   (parse_array == 19).astype(np.float32))\n",
    "\n",
    "    agnostic = img.copy()\n",
    "    agnostic_draw = ImageDraw.Draw(agnostic)\n",
    "\n",
    "    length_a = np.linalg.norm(pose_data[5] - pose_data[2])\n",
    "    length_b = np.linalg.norm(pose_data[12] - pose_data[9])\n",
    "    point = (pose_data[9] + pose_data[12]) / 2\n",
    "    pose_data[9] = point + (pose_data[9] - point) / length_b * length_a\n",
    "    pose_data[12] = point + (pose_data[12] - point) / length_b * length_a\n",
    "    r = int(length_a / 16) + 1\n",
    "\n",
    "    # mask arms\n",
    "    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 5]], 'gray', width=r * 10)\n",
    "    for i in [2, 5]:\n",
    "        pointx, pointy = pose_data[i]\n",
    "        agnostic_draw.ellipse((pointx - r * 5, pointy - r * 5, pointx + r * 5, pointy + r * 5), 'gray', 'gray')\n",
    "    for i in [3, 4, 6, 7]:\n",
    "        if (pose_data[i - 1, 0] == 0.0 and pose_data[i - 1, 1] == 0.0) or (pose_data[i, 0] == 0.0 and pose_data[i, 1] == 0.0):\n",
    "            continue\n",
    "        agnostic_draw.line([tuple(pose_data[j]) for j in [i - 1, i]], 'gray', width=r * 10)\n",
    "        pointx, pointy = pose_data[i]\n",
    "        agnostic_draw.ellipse((pointx - r * 5, pointy - r * 5, pointx + r * 5, pointy + r * 5), 'gray', 'gray')\n",
    "\n",
    "    # mask torso\n",
    "    for i in [9, 12]:\n",
    "        pointx, pointy = pose_data[i]\n",
    "        agnostic_draw.ellipse((pointx - r * 3, pointy - r * 6, pointx + r * 3, pointy + r * 6), 'gray', 'gray')\n",
    "    agnostic_draw.line([tuple(pose_data[i]) for i in [2, 9]], 'gray', width=r * 6)\n",
    "    agnostic_draw.line([tuple(pose_data[i]) for i in [5, 12]], 'gray', width=r * 6)\n",
    "    agnostic_draw.line([tuple(pose_data[i]) for i in [9, 12]], 'gray', width=r * 12)\n",
    "    agnostic_draw.polygon([tuple(pose_data[i]) for i in [2, 5, 12, 9]], 'gray', 'gray')\n",
    "\n",
    "    # mask neck\n",
    "    pointx, pointy = pose_data[1]\n",
    "    agnostic_draw.rectangle((pointx - r * 7, pointy - r * 7, pointx + r * 7, pointy + r * 7), 'gray', 'gray')\n",
    "    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_head * 255), 'L'))\n",
    "    agnostic.paste(img, None, Image.fromarray(np.uint8(parse_lower * 255), 'L'))\n",
    "\n",
    "    return agnostic\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 경로 설정\n",
    "    input_image_path = 'input/image'  # 변경된 경로\n",
    "    input_pose_path = 'pre-processing/openpose_json'\n",
    "    output_path = 'pre-processing/agnostic-v3.2'\n",
    "\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    for im_name in tqdm(os.listdir(input_image_path)):\n",
    "        if not im_name.endswith('.jpg'):\n",
    "            continue\n",
    "\n",
    "        # 포즈 데이터 로드\n",
    "        pose_name = im_name.replace('.jpg', '_keypoints.json')\n",
    "        try:\n",
    "            with open(osp.join(input_pose_path, pose_name), 'r') as f:\n",
    "                pose_label = json.load(f)\n",
    "                pose_data = pose_label['people'][0]['pose_keypoints_2d']\n",
    "                pose_data = np.array(pose_data).reshape((-1, 3))[:, :2]\n",
    "        except (IndexError, KeyError, FileNotFoundError) as e:\n",
    "            print(f\"Error processing pose data for {pose_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 이미지와 레이블 데이터 로드\n",
    "        img = Image.open(osp.join(input_image_path, im_name))\n",
    "        parse_name = im_name.replace('.jpg', '.png')\n",
    "        try:\n",
    "            parse = Image.open(osp.join(input_image_path.replace(\"image\", \"image-parse\"), parse_name))\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error processing parse image for {parse_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 마스킹 처리\n",
    "        agnostic = get_img_agnostic(img, parse, pose_data)\n",
    "\n",
    "        # 결과 저장\n",
    "        agnostic.save(osp.join(output_path, im_name))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
